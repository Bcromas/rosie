{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = spark.read.parquet(\"/var/reddit-parquet\") # believe these are Subreddit Submissions, Comments (children of Submissions) do not seem to be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      " |-- adserver_click_url: string (nullable = true)\n",
      " |-- adserver_imp_pixel: string (nullable = true)\n",
      " |-- approved_by: string (nullable = true)\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- banned_by: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- body_html: string (nullable = true)\n",
      " |-- clicked: boolean (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created: long (nullable = true)\n",
      " |-- created_utc: string (nullable = true)\n",
      " |-- disable_comments: boolean (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- downs: long (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- from: string (nullable = true)\n",
      " |-- from_id: string (nullable = true)\n",
      " |-- from_kind: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- hidden: boolean (nullable = true)\n",
      " |-- hide_score: boolean (nullable = true)\n",
      " |-- href_url: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- imp_pixel: string (nullable = true)\n",
      " |-- is_self: boolean (nullable = true)\n",
      " |-- likes: boolean (nullable = true)\n",
      " |-- link_flair_css_class: string (nullable = true)\n",
      " |-- link_flair_text: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- locked: boolean (nullable = true)\n",
      " |-- media: string (nullable = true)\n",
      " |-- media_embed: struct (nullable = true)\n",
      " |    |-- content: string (nullable = true)\n",
      " |    |-- height: long (nullable = true)\n",
      " |    |-- scrolling: boolean (nullable = true)\n",
      " |    |-- width: long (nullable = true)\n",
      " |-- mobile_ad_url: string (nullable = true)\n",
      " |-- mod_reports: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- num_comments: long (nullable = true)\n",
      " |-- num_reports: long (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- post_hint: string (nullable = true)\n",
      " |-- preview: struct (nullable = true)\n",
      " |    |-- images: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- resolutions: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |-- source: struct (nullable = true)\n",
      " |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |-- variants: struct (nullable = true)\n",
      " |    |    |    |    |-- gif: struct (nullable = true)\n",
      " |    |    |    |    |    |-- resolutions: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |    |-- source: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |-- mp4: struct (nullable = true)\n",
      " |    |    |    |    |    |-- resolutions: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |    |-- source: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |-- promoted: boolean (nullable = true)\n",
      " |-- quarantine: boolean (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- replies: string (nullable = true)\n",
      " |-- report_reasons: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- saved: boolean (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- score_hidden: boolean (nullable = true)\n",
      " |-- secure_media: struct (nullable = true)\n",
      " |    |-- content: string (nullable = true)\n",
      " |    |-- event_id: string (nullable = true)\n",
      " |    |-- height: long (nullable = true)\n",
      " |    |-- oembed: struct (nullable = true)\n",
      " |    |    |-- author_name: string (nullable = true)\n",
      " |    |    |-- author_url: string (nullable = true)\n",
      " |    |    |-- cache_age: long (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- height: long (nullable = true)\n",
      " |    |    |-- html: string (nullable = true)\n",
      " |    |    |-- mean_alpha: double (nullable = true)\n",
      " |    |    |-- provider_name: string (nullable = true)\n",
      " |    |    |-- provider_url: string (nullable = true)\n",
      " |    |    |-- thumbnail_height: long (nullable = true)\n",
      " |    |    |-- thumbnail_url: string (nullable = true)\n",
      " |    |    |-- thumbnail_width: long (nullable = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- version: string (nullable = true)\n",
      " |    |    |-- width: long (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- width: long (nullable = true)\n",
      " |-- secure_media_embed: struct (nullable = true)\n",
      " |    |-- content: string (nullable = true)\n",
      " |    |-- height: long (nullable = true)\n",
      " |    |-- scrolling: boolean (nullable = true)\n",
      " |    |-- width: long (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- selftext_html: string (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- third_party_tracking: string (nullable = true)\n",
      " |-- third_party_tracking_2: string (nullable = true)\n",
      " |-- thumbnail: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- ups: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- user_reports: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- over_18: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_count = reddit.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859977347"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_count # 1% of this is +28 million"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### The DataFrame we created has a fairly large number of columns (70), is deeply nested in several instances (up to 8 layers deep), and contains a significant number of records (+2.8 billion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a subset of columns for EDA\n",
    "\n",
    "these_cols = [\n",
    "    \"id\",\n",
    "    \"parent_id\",\n",
    "    \"subreddit\",\n",
    "    \"author\",\n",
    "    \"created\",\n",
    "    \"body\",\n",
    "    \"num_comments\",\n",
    "    \"score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### For our initial EDA we primarily care about the columns indicated above so we'll subset the data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('parent_id', 'string'),\n",
       " ('subreddit', 'string'),\n",
       " ('author', 'string'),\n",
       " ('created', 'bigint'),\n",
       " ('body', 'string'),\n",
       " ('num_comments', 'bigint'),\n",
       " ('score', 'bigint')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_df = reddit.select(these_cols)\n",
    "cols_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### It's worthwhile to check the data types of the columns. You may notice that \"created\" is a bigint where the created date is represented in Unix time/Epoch time (the number of seconds since January 1, 1970). We'll want to convert that to a more human readable format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Created date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert \"created\" from bigint to string\n",
    "cols_df = cols_df.withColumn(\n",
    "    \"created\", \n",
    "    cols_df[\"created\"].cast(\"string\")\n",
    ")\n",
    "\n",
    "# add new col showing just created year\n",
    "cols_df = cols_df.withColumn(\n",
    "    \"created_year\", \n",
    "    from_unixtime(\n",
    "        cols_df[\"created\"], \n",
    "        \"yyyy\" # full timestamp: yyyy-MM-dd HH:mm:ss.SS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|created_year|     count|\n",
      "+------------+----------+\n",
      "|        null|2694014185|\n",
      "|        2006|      1817|\n",
      "|        2007|    279724|\n",
      "|        2008|   2527732|\n",
      "|        2009|   4854283|\n",
      "|        2010|   7064885|\n",
      "|        2011|  15047383|\n",
      "|        2012|  18504969|\n",
      "|        2013|     24296|\n",
      "|        2014|  52893169|\n",
      "|        2015|  64764904|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "years_df = cols_df.groupby(\"created_year\").count()\n",
    "years_df.orderBy(\"created_year\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### The data covers 9 years from 2006 to 2015. Although a significant portion of the data is missing a created year. There are also years that have several orders of magnitude fewer records than other years (e.g. 2006 and 2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = cols_df[cols_df[\"created_year\"].isNull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2694014185"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((null_count/record_count)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Overall, 94% of the records in cols_df have a null value for \"created_year\". While it may seem like our data is useless it isn't. We should be able to work with the remaining ~6% which represent +165 million records. Although, this number will also decrease when we account for nulls in \"body\" and other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279383793"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_df[cols_df[\"body\"].isNull()].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Unfortunately, there are a significant number of records with null values in \"body\" too. I wasn't expecting this much data to be missing. Regardless, we'll continue with our EDA to see what value, if any, there may be in using this data source for additional tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = cols_df[\n",
    "    (cols_df[\"created_year\"].isNotNull())&\n",
    "    (cols_df[\"body\"].isNotNull())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+-------------+\n",
      "|      subreddit|count|posts_per_day|\n",
      "+---------------+-----+-------------+\n",
      "|      AskReddit|45486|        13.85|\n",
      "|leagueoflegends|11784|         3.59|\n",
      "|          funny| 8968|         2.73|\n",
      "|      worldnews| 7410|         2.26|\n",
      "| DestinyTheGame| 7209|         2.19|\n",
      "|           pics| 6870|         2.09|\n",
      "|  AdviceAnimals| 6642|         2.02|\n",
      "|            nfl| 6611|         2.01|\n",
      "|  todayilearned| 5554|         1.69|\n",
      "|          DotA2| 4925|          1.5|\n",
      "+---------------+-----+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_days = 9*365\n",
    "\n",
    "subreddit_df = clean_df.groupby(\"subreddit\").count()\n",
    "subreddit_df = subreddit_df.withColumn(\"posts_per_day\", round(subreddit_df[\"count\"]/total_days,2))\n",
    "subreddit_df.orderBy(\"count\", ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### The amount of usable data continues to shrink as we dig deeper...the Subreddit with the most records with non-null values in \"body\" is AskReddit which amounts to approximately 5,000 records per year or 13 records per day.\n",
    "\n",
    "> ### Is an average of 13 records (with actual content in the body) per day representative of what's posted to Reddit?\n",
    "\n",
    "> ### While I could not find official statistics from Reddit itself, I did find a 3rd party site that purports to track statistics on Subreddits. For instance, it shows that in a recent 24-hour period AskReddit received +12,000 Posts, funny received +1,300, worldnews received 657, and nfl received ~20.\n",
    "\n",
    "> ### A simple \"gut check\" also indicates these numbers are not accurate and the data set is unreliable. While several of the Subreddits are defaults for new users (e.g. AskReddit, funny), AdviceAnimals and nfl are not. \n",
    "\n",
    "The AskReddit Subreddit features +28 million members, It appears this data set is no where near representative of the number of Posts on Subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stratify by created year\n",
    "\n",
    "# cols_df.sampleBy(\"created_year\", {1: 0.01}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can still evaluate distributions of scores & body_len for certain (common) Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
